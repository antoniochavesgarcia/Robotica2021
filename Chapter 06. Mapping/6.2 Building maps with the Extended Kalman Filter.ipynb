{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Building maps with the Extended Kalman Filter - The Nirvana shopping mall\n",
    "\n",
    "The managers behind the **<span style=\"color:seagreen\">Nirvana shopping mall</span>**, in the scope of their *experiencing the future* plan, have contacted **<span style=\"color:seagreen\">UMA-MR</span>** (our brand-new mobile robotics company at UMA) looking for mobile robots able to guide their visitors between different points of interest in their facilities, like information points, the entrance to relevant (paying well) shops, rescue points, etc. \n",
    "\n",
    "<br /><br />\n",
    "<center>\n",
    "<img src=\"./images/nirvana-logo.png\" width=\"600\">\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "These managers have placed identifying marks close to the points of interest they want to consider, but do not know their exact location in the mall. **Our mission as engineers at *UMA-MR* is to build a map of the mall containing such points, so the robot can operate within it.** We are going to use for that an **Extended Kalman Filter (EKF)**.\n",
    "\n",
    "Fortunately, our company has developed a system able to provide the exact location of our robots at each time instant, which are also equipped with a range-and-bearing nosiy sensor able to detect the identifying marks and take measurements to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Formalizing the problem\n",
    "\n",
    "Since we are going to build a map of $N$ landmarks, the position of those landmarks in the map $m$ are the random variables to be estimated. In this way, the state vector in the mapping case is defined as:\n",
    "\n",
    "$$m = [m_1, m_2, \\cdots, m_N] = \n",
    "[x_1, y_1, \\underbrace{x_2, y_2}_{\\text{Position of}\\\\\\text{landmark 2}}, \\dots,x_N, y_N]^T, \\ \\ \\ len(m) = 2N$$\n",
    "\n",
    "In other words, we pursuit the estimation of the probability distribution:\n",
    "\n",
    "$$p(m | z_{1:t}, x_{1:t})$$\n",
    "\n",
    "being $z_{1:t}$ the sensor measurements taken until time instant $t$, and $x_{1:t}$ the robot poses from which those measurements were acquired. Recall that a sensor measurement is related to the pose $x$ and the map $m$ by means of the **observation function**:\n",
    "\n",
    "$$z = h(x,m) + e \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, e \\sim N(0,Q)$$\n",
    "\n",
    "Two assumptions are made when building maps using EFK.\n",
    "\n",
    "#### Assumption 1: each landmark position is estimated independently\n",
    "\n",
    "For simplifying the problem, it is usual to assume that the estimation of the position of the landmarks is independent one to another, only depending each one on its observations, so:\n",
    "\n",
    "$$p(m_i|z_{1:t}, x_{1:t}) = p(m_i |z^i_{1:t}, x_{1:t})$$\n",
    "\n",
    "which results in the following simplification:\n",
    "\n",
    "$$p(m | z_{1:t}, x_{1:t})= p(m_1, m_2, \\cdots, m_N | z_{1:t}, x_{1:t}) = \\prod_{k=1}^N p(m_i | z^i_{1:t}, x_{1:t})$$\n",
    "\n",
    "As a consequence of this, the estimation of, for example, 3 landmarks simultaneously is the same as using three concurrent and independent EKFs for estimating them. \n",
    "\n",
    "#### Assumption 2: the map is static\n",
    "\n",
    "Unlike the localization case, where the robot pose changed over time, in this case it is assumed that the map is static, that is, the landmarks are still. This means that in the state transition model $m_k=m_{k-1}$, that is:\n",
    "\n",
    "$$m_t = A_t m_{t-1} + B_t u_t + \\epsilon_t \\ \\ \\ \\ (A=I, u=0, \\epsilon=0)$$\n",
    "\n",
    "So good news here!, there is no need for a prediction step in the EKF, we only have to model the correction (update) one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Developing the EKF filter for mapping the mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.tcomp import tcomp\n",
    "from utils.AngleWrap import AngleWrap\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.Jacobians import J2\n",
    "from utils.unit6.MapCanvas import MapCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The provided robot\n",
    "\n",
    "Take a look at the following ``EFKMappingRobot()`` class, which is already provided by your colleagues at **<span style=\"color:seagreen\">UMA-MR</span>**, modeling **a robot equipped with a range and bearing sensor**, which is able to keep the following information:\n",
    "- ``true_pose``: The exact pose of the robot in the environment, which is perfectly known.\n",
    "- ``Q``: Uncertainty of the range and bearing sensor, which has the form:\n",
    "$\\Sigma_{r\\theta} = \\begin{bmatrix} \\sigma^2_r & 0 \\\\ 0 & \\sigma^2_\\theta  \\end{bmatrix}$\n",
    "- ``xEst``: Vector with the estimated state, in this case the position of the $M$ observed landmarks: $[x_1, y_1, x_2, y_2, \\dots,x_M, y_M]^T$. Its size changes over time with the detection of previously unobserved landmarks.\n",
    "- ``PEst``: uncertainty associated with those predictions, with size ($M\\times2$,$M\\times2$). Its size also changes over time.\n",
    "- ``MappedLandmarks``: A vector with length equal to the number of landmarks in the map ($N$), which elements can take the following values:\n",
    "  - ``-1`` if the landmark with that index has not benn seen yet.\n",
    "  - ``idx_in_xEst``: an odd number indicating the position of that landmark in ``xEst``.\n",
    "  For example, if during the robot operation in a map with 5 landmarks, it first detect the landmark with id 2, and later the one with id 4, the content of this vector would be ``MappedLandmarks=[-1,-1,1,-1,3]``.\n",
    "\n",
    "and to perform the following actions:\n",
    "\n",
    "- ``step()``: Performs a motion command, without noise. \n",
    "- ``observe()``: Returns a range and bearing measurement (in polars) to a given landmark in the map.\n",
    "- ``get_random_observation()``: Returns a range and bearing measurement (in polars) to a random landmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFKMappingRobot():\n",
    "    def __init__(self, true_pose, sigma_r, sigma_theta, n_features):\n",
    "        # Robot description\n",
    "        self.true_pose = true_pose\n",
    "        self.Q = np.diag([sigma_r, sigma_theta])**2\n",
    "        \n",
    "        # Map -- Initially empty\n",
    "        self.xEst = np.empty((0, 0))\n",
    "        self.PEst = np.empty((0, 0))\n",
    "        self.QEst = 1.0*self.Q\n",
    "        \n",
    "        self.MappedLandmarks = -1*np.ones((n_features,1), int)\n",
    "        \n",
    "    def step(self, u):\n",
    "        self.true_pose = tcomp(self.true_pose, u)\n",
    "        \n",
    "    def observe(self, idx, world, noisy=True):\n",
    "        \"\"\" Generate a observation of a feature in our world\n",
    "        \n",
    "            Args:\n",
    "                world: Complete map of all landmarks in the world\n",
    "                idx: Landmark to observe (index in world matrix)\n",
    "                noisy: Add noise to z, prorportional to self.Q\n",
    "                \n",
    "            Returns:\n",
    "                z: One range and bearing observation\n",
    "        \"\"\"\n",
    "        \n",
    "        z = np.empty((2, 1))\n",
    "        delta = world[:, [idx]] - self.true_pose[0:2, :]\n",
    "        \n",
    "        # Range\n",
    "        z[0, :] = np.sqrt(np.sum(delta**2))\n",
    "        # Bearing\n",
    "        z[1, :] = np.arctan2(delta[1, 0],delta[0, 0]) - self.true_pose[2, 0]\n",
    "        z[1, :] = AngleWrap(z[1, :])\n",
    "        \n",
    "        if noisy:\n",
    "            z = z + np.sqrt(self.Q)@random.randn(2,1)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def get_random_observation(self, world, noisy=True):\n",
    "        iLandmarks = world.shape[1]\n",
    "        iLandmark = random.randint(iLandmarks)\n",
    "        z = self.observe(iLandmark, world, noisy)\n",
    "        return z, [iLandmark]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction step\n",
    "\n",
    "As commented, the map is considered static, so the prediction step is reduced to consider as the predicted landmarks' positions the ones estimated in the previous step. The same holds for the predicted uncertainty, so this steps results in something like this:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}\n",
    "       \\verb!def !& \\verb!ExtendedKalmanFilter!(m_{t-1},\\Sigma_{t-1}, z_t): \\\\\n",
    "      & \\textbf{Prediction.} \\\\\n",
    "      & \\bar m_t = m_{t-1} &\\text{(1. Map prediction)}\\\\\n",
    "      & \\bar\\Sigma_t = \\Sigma_{t-1} &\\text{(2. Uncertainty of prediction)}\\\\      \n",
    "  \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Implementing the naive prediction step</i></b></span>** \n",
    "\n",
    "**You are tasked to** implement the previous behavior in the following function, which performs the prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_step(robot: EFKMappingRobot): \n",
    "    \"\"\" Performs the prediction step of the EKF algorithm for mapping\n",
    "            robot: Robot base (contains state map: xEst, PEst)\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "            xPred: Predicted position of the landmarks\n",
    "            PPred: Predicted uncertainty of the landmarks positions\n",
    "    \"\"\"    \n",
    "    \n",
    "    # We assume that the map is static \n",
    "    xPred = robot.xEst\n",
    "    PPred = robot.PEst\n",
    "    \n",
    "    return xPred, PPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **test your function** with the next code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xPred:\n",
      "[[0.5]\n",
      " [0.7]]\n",
      "PPred:\n",
      "[[1.32 0.  ]\n",
      " [0.   0.8 ]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "xVehicleTrue = np.vstack([0.5, 0.7, 0]) # We know the exact robot pose at any moment\n",
    "robot = EFKMappingRobot(xVehicleTrue, 1, 0.8, 1)\n",
    "robot.xEst = np.vstack([.5, .7])\n",
    "robot.PEst = np.diag([1.32, 0.8])\n",
    "[xPred,PPred] = prediction_step(robot)\n",
    "print('xPred:\\n' + str(xPred))\n",
    "print('PPred:\\n' + str(PPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "xPred:\n",
    "[[0.5]\n",
    " [0.7]]\n",
    "PPred:\n",
    "[[1.32 0.  ]\n",
    " [0.   0.8 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing a landmark for first time\n",
    "\n",
    "When the sensor onboard the robot detects a landmark for the first time, there is no need to do the EKF update step (indeed, since there is not previously knowledge about the landmark, there is nothing to update). Instead, we have to properly modify 1) the vector of estimated landmark positions, and 2) their associated uncertainties, to accommodate this new information:\n",
    "\n",
    "\n",
    "1. **Modifying the state vector**: Insert the position of the new observed landmark $[x_{M+1},y_{M+1}]$, using the sensor measurement $z_k=[r_k,\\theta_k]$, at the end of the vector containing the estimated positions ``xEst``, so: $\\\\[10pt]$\n",
    "$$xEst=[x_1,y_y, \\cdots, x_M, y_M, x_{M+1}, y_{M+1}]\\\\[5pt]$$ \n",
    "Since the measurment is provided in polar coordinates in the robot local frame, we have to convert them first to cartensians and then to the world frame using the robot pose $[x_v,y_v]'$. The function in charge of doing so can be defined as:\n",
    "\n",
    "$$ \n",
    "f(x_v,z_k)=\\begin{bmatrix} x_{M+1} \\\\ y_{M+1} \\end{bmatrix} =\n",
    "\\begin{bmatrix} x_v \\\\ y_v \\end{bmatrix} + \n",
    "r_k\\begin{bmatrix} cos \\alpha_k \\\\ sin \\alpha_k \\end{bmatrix}\n",
    ", \\ \\ \\alpha_k = \\theta_k + \\theta_v\n",
    "$$\n",
    "\n",
    "2. **Extending the covariance matrix**. In order to acomodate the uncertainty regarding the position of the new landmark, we have to extend the covariance matrix in the following way: $\\\\[10pt]$\n",
    "$$\n",
    "PEst=\\begin{bmatrix}\n",
    "    [\\Sigma^1_{xy}]_{2 \\times 2} & \\cdots & 0_{2 \\times 2} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    0_{2 \\times 2} & \\cdots & [\\Sigma^{M+1}_{xy}]_{2 \\times 2}\n",
    "  \\end{bmatrix}_{2n \\times 2n}\n",
    "  $$  \n",
    "Notice that the covariance $\\Sigma^{M+1}_{xy}$ stands for the uncertainty in the measurement expressed in the world cartesian coordinates, retrieved by: $\\\\[10pt]$\n",
    "$$\\Sigma^{M+1}_{xy} = J \\Sigma^{M+1}_{r\\theta} J^T \\\\[5pt]$$ \n",
    "being $\\Sigma^{M+1}_{r\\theta}$ the uncertainty characterizing the sensor measurements (``QEst`` in our code), and $J$ (``jGz`` in our code) the jacobian of the function $f(x_v,z_k)$ that expresses the measurement in global coordinates, which is: $\\\\[10pt]$\n",
    "$$\n",
    "J =  \\begin{bmatrix} \\partial x / \\partial r  &  \\partial x / \\partial \\theta \\\\ \\partial y / \\partial r & \\partial y / \\partial \\theta \\end{bmatrix} =\n",
    "\\begin{bmatrix} cos \\alpha & -r sin \\alpha \\\\ sin \\alpha & r cos \\alpha \\end{bmatrix} \\\\[10pt]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Incorporating a landmark detected for first time</i></b></span>** \n",
    "\n",
    "**Your work here is to:**\n",
    "- Complete the ``get_new_landmark_jacobians()`` to compute the jacobian $J$.\n",
    "- Complete the ``incorporate_new_landmark()`` method to modify the state vector ``xEst`` and the convariance matrix ``PEst`` as explained above. We will make use of the [`linalg.block_diag()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.block_diag.html) function at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_landmark_jacobians(Xv, z):\n",
    "    \"\"\" Calculate the jacobian for transforming an observation to the world frame\n",
    "    \n",
    "        Args:\n",
    "            Xv: True pose of our robot\n",
    "            z: Observation of a landmark. In polar coordinates from the p.o.v. of our robot.\n",
    "        \n",
    "        Returns:\n",
    "            2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    r, a = z[0], z[1]\n",
    "    c, s = np.cos(a), np.sin(a)\n",
    "    \n",
    "    jGz = np.array([\n",
    "        [c, -r*s],\n",
    "        [s, r*c]\n",
    "    ])\n",
    "    return jGz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it working properly? **Try it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jGz:\n",
      "[[[ 0.93937271]\n",
      "  [-0.41147737]]\n",
      "\n",
      " [[ 0.34289781]\n",
      "  [ 1.12724726]]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "z = np.vstack([1.2,0.35])\n",
    "Xv = np.vstack([2, 2.1, 0])\n",
    "jGz = get_new_landmark_jacobians(Xv, z)\n",
    "print('jGz:\\n' + str(jGz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "jGz:\n",
    "[[ 0.93937271 -0.41147737]\n",
    " [ 0.34289781  1.12724726]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorporate_new_landmark(robot: EFKMappingRobot, z, iLandmark, xPred, PPred):\n",
    "    \"\"\" Incorporates the information relative to a new ladmark to our system\n",
    "        robot: Robot base (contains state map: xEst, PEst)\n",
    "        z: Observation of a landmark\n",
    "        iLandmark: Index of z in the world map\n",
    "        xPred: Predicted map\n",
    "        PPred: Uncertainty of the prediction\n",
    "\n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    # This is a new feature, so add it to the map        \n",
    "        \n",
    "    # The observation is in the local frame of the robot, it has to\n",
    "    # be translated to the global frame\n",
    "    xLandmark = np.vstack([ (z[0]*np.cos(z[1])) , (z[0]*np.sin(z[1])) ])\n",
    "\n",
    "    # Add it to the current state\n",
    "    nStates = xPred.size \n",
    "        \n",
    "    if nStates == 0:\n",
    "        robot.xEst = xLandmark\n",
    "    else:\n",
    "        robot.xEst = np.vstack([robot.xEst, xLandmark]) #Each new feature two new rows\n",
    "\n",
    "    # Compute the jacobian\n",
    "    jGz = get_new_landmark_jacobians(robot.true_pose, z) #Dimension 2x2\n",
    "    \n",
    "    # Build a matrix M incorporating the jacobian to multiply the extendend PEst matrix by it (see below)\n",
    "    if nStates != 0:\n",
    "        # note we don't use jacobian w.r.t vehicle since the pose doesn’t have uncertainty\n",
    "        M = np.vstack([  \n",
    "                np.hstack([M, np.zeros((nStates, 2))]),\n",
    "                np.hstack([np.zeros((2, nStates)), jGz])\n",
    "            ])\n",
    "    else: \n",
    "        # First landmark observed!\n",
    "        M = jGz\n",
    "            \n",
    "    print(robot.PEst)\n",
    "    robot.PEst = M@linalg.block_diag(robot.PEst, robot.QEst)@M.T\n",
    "\n",
    "    #This can also be done directly PEst = [PEst,zeros(nStates,2);\n",
    "                                            # zeros(2,nStates),\n",
    "                                            # jGz*QEst*jGz']\n",
    "\n",
    "    #remember this landmark as being mapped: we store its ID for the state vector\n",
    "    robot.MappedLandmarks[iLandmark] = robot.xEst.size-2 #Always an odd number\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The correction (update) step\n",
    "\n",
    "Once a landmark has been detected and its provided information (location and uncertainty) has been properly incorporated to our mapping system, such an information can be updated with new measurements of such a landmark. For doing so, the EKF algorithm performs the following steps:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}     \n",
    "      & \\textbf{Correction.} \\\\\n",
    "      & K_t = \\bar\\Sigma_t H^T_t (H_t \\bar\\Sigma_t H^T_t + Q_t)^{-1} &\\text{(3. Kalman gain)}\\\\\n",
    "      & m_t = \\bar m_t + K_t (z_t - h(x_t,\\bar m_t)) &\\text{(4. Map estimation)}\\\\\n",
    "      & \\Sigma_t = (I - K_t H_t) \\bar\\Sigma_t &\\text{(5. Uncertainty of estimation)}\\\\\n",
    "      & \\verb!return ! m_t, \\Sigma_t\n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "Notice that the map (landmark locations) is estimated according to the map estimation in the previous time step $t-1$, the *Kalman gain*, and the error (also called ***innovation***) between the obsevation taken by the sensor ($z_t$) and the one computed by the observation model given the robot pose and the predicted map, that is $z_t - h(x_t,\\bar m_t$).\n",
    "\n",
    "In such equations, H (``jH`` in our code) represents the jacobian of the observation model. The shape of such a jacobian is $(2,M\\times2)$, and has the following form:\n",
    "\n",
    "$$\n",
    "H = \\left[\n",
    "  \\begin{matrix}\n",
    "0 & 0 & \\cdots \\\\\n",
    "0 & 0 & \\cdots \\\\\n",
    "\\end{matrix}\n",
    "\\right .\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "jHxl_{11} & jHxl_{12} \\\\\n",
    "jHxl_{21} & jHxl_{22} \\\\\n",
    "\\end{bmatrix}}_\\text{Jacobian for the observed landmark, $jHxl$}\n",
    "\\left .\n",
    "\\begin{matrix}\n",
    "\\cdots & 0 & 0 \\\\\n",
    "\\cdots & 0 & 0 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "jHxl = \n",
    "\\begin{bmatrix}\n",
    "(x_l - x)/d & (y_l - y)/d \\\\\n",
    "-(y_l - y)/d^2 & (x_l - x)/d^2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $[x_l,y_l]$ is the position of the landmark, $[x,y]$ is the robot location, and $d=\\sqrt{(x_l-x)^2 + (y_l-y)^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Updating the knowledge about an observed landmark</i></b></span>** \n",
    "\n",
    "**Your job at this point is:**\n",
    "\n",
    "- To implement the function ``get_observation_jacobian()`` returning the jacobian of the observed landmark, that is, $jHxl$.\n",
    "- To complete the ``update_step()`` method that performs the update step of the EKF algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_jacobian(xPred, xLandmark):\n",
    "    \"\"\" Calculate the jacobian of the observation model.\n",
    "        \n",
    "        Needed to update a landmark we have already seen.\n",
    "        Hint. Similar to the one described in unit 5 (Localization)\n",
    "        \n",
    "        Args:\n",
    "            xPred: True pose of our robot.\n",
    "            xLandmark: Estimated pose of a landmark in our map. World p.o.v in cartesian coordinates.\n",
    "                Does not contain an angle.\n",
    "        \n",
    "        Return:\n",
    "            jHxl: 2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    delta = xLandmark - xPred[0:2]\n",
    "    \n",
    "    xdist = delta[0]\n",
    "    ydist = delta[1]\n",
    "    r = np.sqrt( xdist**2 + ydist**2)\n",
    "    r2 = r**2\n",
    "    jHxl = np.array([\n",
    "        [ xdist/r  ,  ydist/r],\n",
    "        [-ydist/r2 , xdist/r2]\n",
    "    ])\n",
    "    return jHxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if your implementation is right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jHxl:\n",
      "[[[ 0.98058068]\n",
      "  [-0.19611614]]\n",
      "\n",
      " [[ 0.38461538]\n",
      "  [ 1.92307692]]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "xLandmark = np.vstack([2.5,2])\n",
    "xPred = np.vstack([2, 2.1, 0])\n",
    "jHxl = get_observation_jacobian(xPred, xLandmark)\n",
    "print('jHxl:\\n' + str(jHxl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "jHxl:\n",
    "[[ 0.98058068 -0.19611614]\n",
    " [ 0.38461538  1.92307692]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(robot, z, iLandmark, xPred, PPred):\n",
    "    \"\"\" Performs the update step of EKF\n",
    "        robot: Robot base (contains state map: xEst, PEst)\n",
    "        z: Observation of a landmark\n",
    "        iLandmark: Index of z in the world map\n",
    "        xPred: Predicted map\n",
    "        PPred: Uncertainty of the prediction\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    # Find out where it is in state vector\n",
    "    landmarkIndex = robot.MappedLandmarks[iLandmark[0], 0]\n",
    "        \n",
    "    # xLandmark is the current estimation of the position of the\n",
    "    # landmard \"FeatureIndex\"\n",
    "    xLandmark = xPred[landmarkIndex:landmarkIndex+2]\n",
    "        \n",
    "    # DONE Predicts the observation\n",
    "    zPred = robot.observe(0, xLandmark, noisy=False) # Hint: use robot.observe function\n",
    "\n",
    "    # Get observation Jacobians\n",
    "    jHxf = get_observation_jacobian(robot.xEst, zPred)\n",
    "        \n",
    "    # Fill in state jacobian\n",
    "    # (the jacobian is zero except for the observed landmark)\n",
    "    jH = np.zeros((2, xPred.size))\n",
    "    jH[:, landmarkIndex:landmarkIndex+2] = jHxf\n",
    "        \n",
    "    #\n",
    "    # Kalman update\n",
    "    #\n",
    "    Innov = xLandmark-zPred # Innovation\n",
    "    Innov[1] = AngleWrap(Innov[1])\n",
    "    S = jH@PPred@jH.T + robot.QEst\n",
    "    K = PPred@jH.T@linalg.inv(S) # Gain\n",
    "    robot.xEst = xPred + K@Innov    \n",
    "    robot.PEst = (np.eye(robot.PEst.shape[0]) - K@jH)@PPred\n",
    "    #robot.PEst = PPred - K@S@K.T # Alternative way\n",
    "    \n",
    "    #ensure P remains symmetric\n",
    "    robot.PEst = 0.5*(robot.PEst+robot.PEst.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Putting all together in the EKF algorithm</i></b></span>** \n",
    "\n",
    "Now that you have implemented the building blocks of the EKF filter for mapping the **<span style=\"color:seagreen\">Nirvana shopping mall</span>**, it is time to write a simple function ``EKFMapping()`` putting them together. For that, **you have to** call each method with the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EKFMapping(robot: EFKMappingRobot, z, iLandmark):\n",
    "    \"\"\" EFK algorithm for mapping\n",
    "        \n",
    "            robot: Robot base (contains state map: xEst, PEst)\n",
    "            z: Observation of a landmark\n",
    "            iLandmark: Index of z in the world map\n",
    "    \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do prediction step\n",
    "    [xPred, PPred] = prediction_step(robot)\n",
    "\n",
    "    # Check if feature observed is in map\n",
    "    if robot.MappedLandmarks[iLandmark] > -1:\n",
    "        update_step(robot, z, iLandmark, xPred, PPred)\n",
    "        \n",
    "    else:\n",
    "        # This is a new feature, so add its information to the map        \n",
    "        incorporate_new_landmark(robot, z, iLandmark, xPred, PPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 Testing the mapping system\n",
    "\n",
    "### Playing with one landmark\n",
    "\n",
    "Let's consider that the mall has only one landmark to get things started (``nLandmarks=1``). The following function provides a demo where the robot is commanded to follow a squared trajectory while observing a landmark after each movement. \n",
    "\n",
    "The **<span style=\"color:seagreen\">Nirvana</span>** managers are curious about the state and dimensions of the variables storing the estimated positions `xEst` and their associated uncertainties `Pest`, so we show their content after each 5 iterations of the algorithm. \n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-2.png\" width=\"500\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 1: Example run of the EKF algorithmn for mapping (only one landmark). <br/>\n",
    "      it shows the true pose (in red), <br/>\n",
    "      the real pose of the landmark (as a green star), <br/>\n",
    "      and the estimation from the EKF algorithm (pose and confidence ellipse).\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_ekf_mapping(robot,\n",
    "                     Map,\n",
    "                     nLandmarks,\n",
    "                     mode='non_stop',\n",
    "                     logger=None,\n",
    "                     nSteps=100, # Number of motions\n",
    "                     turning= 40, # Number of motions before turning (square path)\n",
    "                     print_each=2):\n",
    "    \n",
    "    %matplotlib notebook\n",
    "    if mode == 'step_by_step':\n",
    "        matplotlib.use('TkAgg')\n",
    "\n",
    "    # storing the number of times a landmark has been seen\n",
    "    # also store the handler to the graphical info shown\n",
    "    canvas = MapCanvas(nLandmarks)\n",
    "    \n",
    "    canvas.ax.plot(Map[0, :], Map[1, :], 'g*')\n",
    "    hObsLine = canvas.ax.plot([0,0], [0,0], linestyle=':')\n",
    "    \n",
    "    # Control action\n",
    "    u = np.zeros((3, 1))\n",
    "    u[0] = (2.*MapSize/1.5)/turning\n",
    "    u[1] = 0.\n",
    "    \n",
    "    # Start the loop!\n",
    "    for k in range(nSteps):\n",
    "        #\n",
    "        # Move the robot\n",
    "        #\n",
    "        u[2]=0.\n",
    "        if k%turning == turning-1:\n",
    "            u[2] = np.pi/2\n",
    "        \n",
    "        robot.step(u) # Perfectly known robot pose\n",
    "        \n",
    "        z, iLandmark = robot.get_random_observation(world=Map)\n",
    "        \n",
    "        # Update the \"observedtimes\" for the feature and plot the reading\n",
    "        canvas.increment_observed_times(iLandmark)\n",
    "        canvas.PlotNumberOfReadings(robot.true_pose, iLandmark, Map)\n",
    "        \n",
    "        EKFMapping(robot, z, iLandmark)\n",
    "        \n",
    "        # Print map evolution each 5 steps\n",
    "        if not k%5:\n",
    "            with np.printoptions(precision=3):\n",
    "                print('Iteration: ' + str(k))\n",
    "                print('Estimated xEst:\\n' + str(robot.xEst))\n",
    "                print('Estimated PEst:\\n' + str(robot.PEst))\n",
    "                print('---------------------------------')\n",
    "        \n",
    "        # Log important values\n",
    "        if logger is not None:\n",
    "            logger.log(k, robot, Map)\n",
    "        \n",
    "        # Drawings\n",
    "        if k%print_each == print_each-1:\n",
    "            DrawRobot(canvas.fig, canvas.ax,robot.true_pose, 'r')#plot(xVehicleTrue(1),xVehicleTrue(2),'r*')\n",
    "            canvas.DoMapGraphics(robot) # Draw estimated poitns (in black) and ellipses\n",
    "            plt.axis([-MapSize-5, MapSize+5, -MapSize-5, MapSize+5]) # Set limits again\n",
    "            plt.draw()\n",
    "            \n",
    "            if mode == 'step_by_step':\n",
    "                plt.waitforbuttonpress(-1)\n",
    "            elif mode == 'visualize_process':\n",
    "                plt.pause(0.2)\n",
    "            elif mode == 'non_stop':\n",
    "                pass # non stop!\n",
    "\n",
    "    # Final drawings\n",
    "    %matplotlib inline\n",
    "    if logger is not None:\n",
    "        logger.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-736a1e8826fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mrobot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEFKMappingRobot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxVehicleTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSigma_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSigma_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnLandmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdemo_ekf_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMap\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mnLandmarks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-151e746371aa>\u001b[0m in \u001b[0;36mdemo_ekf_mapping\u001b[1;34m(robot, Map, nLandmarks, mode, logger, nSteps, turning, print_each)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlotNumberOfReadings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_pose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLandmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mEKFMapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLandmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Print map evolution each 5 steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e67a186a5b32>\u001b[0m in \u001b[0;36mEKFMapping\u001b[1;34m(robot, z, iLandmark)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# This is a new feature, so add its information to the map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mincorporate_new_landmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miLandmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxPred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPPred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-f87a333570b7>\u001b[0m in \u001b[0;36mincorporate_new_landmark\u001b[1;34m(robot, z, iLandmark, xPred, PPred)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPEst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mrobot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPEst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_diag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPEst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrobot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQEst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m#This can also be done directly PEst = [PEst,zeros(nStates,2);\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)"
     ]
    }
   ],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 1\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 8*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "demo_ekf_mapping(robot, Map ,nLandmarks, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering a larger number of landmarks \n",
    "\n",
    "Once our EKF implementation is working with one landmark, let's try it in a scenario with 5 landmarks. Again, the content of the `xEst` and `Pest` is shown after each 5 iterations of the algorithm.\n",
    "    \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-3.png\" width=\"500\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 2: Execution of the EKF algorithmn for mapping (multiple landmarks). <br/>\n",
    "      Same as in Fig 1., each landmark is accompanied by a number of times observed.\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "demo_ekf_mapping(robot, Map ,nLandmarks, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Having completed these trials, you will be able to **answer the following questions**:\n",
    "\n",
    "In the **one landmark** case:\n",
    "\n",
    "- Discuss the evolution of the variables `xEst` and `Pest`, including their dimensions.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "In the **five landmarks** case:\n",
    "\n",
    "- Why and how the content of the variables `xEst` and `Pest` has change? Discuss their size.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- What structure does the matrix of covariances have? Is there any kind of correlation among the observations of different landmarks?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting performance results\n",
    "\n",
    "As is normal, the contracting company requires some information about how well our EFK implementation performs. For that, your colleagues have implemented a logger, which is meant to store some information each loop regarding the method performance and plot it at the end of its execution. **Execute the following code cells and take a look at that plots!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Logger():\n",
    "    \"\"\" Logs info about the covariance and error of a map.\n",
    "    \n",
    "        Attrs:\n",
    "            n_features: Number of features in the world.\n",
    "            log_error: Matrix to store the error in the fitting for each landmark.\n",
    "            log_det: Matrix to store the determinant of the covariance matrix for each landmark.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_steps, n_features):\n",
    "        \"\"\" Initializes each matrix to log the information\n",
    "        \n",
    "            Args:\n",
    "                n_steps: Maximum number of steps our robot will take.\n",
    "                n_features: Number of features in the world.\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.log_error = np.empty((n_steps,n_features))\n",
    "        self.log_det = np.empty((n_steps,n_features))\n",
    "            \n",
    "    def log(self, k: int, robot: EFKMappingRobot, Map: np.ndarray):\n",
    "        \"\"\" Computes relevant info about the error and covariances.\n",
    "        \n",
    "            It is called once per loop in the demo.\n",
    "        \n",
    "            Args:\n",
    "                k: Number of iteration we are at. Range: [0, n_steps)\n",
    "                robot: \n",
    "                Map:\n",
    "        \"\"\"\n",
    "        for idx in range(self.n_features):\n",
    "            tid = robot.MappedLandmarks[idx,0]\n",
    "            if tid <= -1:\n",
    "                self.log_error[k,idx]= np.Inf\n",
    "                self.log_det[k,idx]=np.Inf\n",
    "            else:\n",
    "                self.log_det[k,idx] = np.linalg.det(robot.PEst[tid:tid+2,tid:tid+2])\n",
    "                self.log_error[k,idx] = np.sqrt(np.sum((robot.xEst[tid:tid+2,0] - Map[:,idx])**2))\n",
    "                \n",
    "    def plot(self):\n",
    "        \"\"\" Plot all relevant figures. It is called at the end of the demo\"\"\"\n",
    "        fig1 , ax1 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2 , ax2 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2.tight_layout()\n",
    "        fig1.tight_layout()\n",
    "\n",
    "        df1 = pd.DataFrame(data= self.log_error, columns = ['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax1.set_title('Error between map and est')\n",
    "        df1.plot(ax = ax1)\n",
    "        df2 = pd.DataFrame(data=np.log(self.log_det), columns=['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax2.set_title('Det. of covar.')\n",
    "        df2.plot(ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "nSteps=100\n",
    "logger = Logger(n_features=nLandmarks, n_steps=nSteps)\n",
    "\n",
    "demo_ekf_mapping(robot,\n",
    "                 Map,\n",
    "                 nLandmarks,\n",
    "                 logger=logger,\n",
    "                 mode='non_stop',\n",
    "                 nSteps=nSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Having taken a look at the logger and its output, you will be able to **answer the following questions**:\n",
    "\n",
    "- What information is shown in the figures produced by the logger?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- The information about the error and the determinant of the covariance is provided for first time at different iterations of the algorithm for each landmark. Is that an error? Why is this happening?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- The error associated to each landmark not always decreases with new observations. Why could this happen?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- On the contrary, the determinant of the covariance matrix associated to each landmark always decreases when new observations are available. Is this an error? Why?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
